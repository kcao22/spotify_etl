{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser as dp\n",
    "import extract_helper_functions as ex\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID & Secret file\n",
    "credentials = pd.read_excel('../logins.xlsx')\n",
    "\n",
    "# Spotify project access credentials\n",
    "session_client_id = credentials['client_id'][0]\n",
    "session_client_secret = credentials['client_secret'][0]\n",
    "session_redirect_url = 'http://localhost:7777/callback'\n",
    "session_scope ='user-read-recently-played'\n",
    "\n",
    "\n",
    "# PostgreSQL access credentials\n",
    "hostname = credentials['hostname'][0]\n",
    "database = credentials['database'][0]\n",
    "username = credentials['username'][0]\n",
    "pwd = credentials['pwd'][0]\n",
    "port_id = credentials['port_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling data from Spotify\n",
    "\n",
    "# Creating Spotipy client object\n",
    "sp = ex.create_spotipy_client(client_id=session_client_id, client_secret=session_client_secret, redirect_uri=session_redirect_url, scope=session_scope)\n",
    "\n",
    "# Getting recent tracks\n",
    "recent_tracks = ex.get_recent_played_tracks(sp, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframes(recent_tracks):\n",
    "    '''\n",
    "    Returns play log, artist, album, and track Pandas DataFrames.\n",
    "    Takes JSON object of recent tracks as returned by Spotify API request and extracts track attributes from JSON object.\n",
    "    Cleans data (dates in particular) and deletes duplicates in tracks, artists, and albums tables.\n",
    "\n",
    "    ARGUMENTS:\n",
    "        recent_tracks: JSON object returned by API request for user's recent songs played from Spotify.\n",
    "    '''\n",
    "    # Instantiate list for list of lists data collection\n",
    "    # Collect datetime today\n",
    "    play_log_fact_data = []\n",
    "    track_dim_data = []\n",
    "    artist_dim_data = []\n",
    "    album_dim_data = []\n",
    "    curr_date = datetime.today().date()\n",
    "\n",
    "    # Traversing tracks and storing data in PySpark DataFrames\n",
    "    # Performing transformations on timezones, date formats during data collection\n",
    "    for i in range(len(recent_tracks['items'])):\n",
    "        # Fact table data\n",
    "        track_id = recent_tracks['items'][i]['track']['id']\n",
    "        artist_id = recent_tracks['items'][i]['track']['album']['artists'][0]['id']\n",
    "        album_id = recent_tracks['items'][i]['track']['album']['id']\n",
    "        track_name = recent_tracks['items'][i]['track']['name']\n",
    "        track_url = recent_tracks['items'][i]['track']['external_urls']['spotify']\n",
    "        track_length_ms = recent_tracks['items'][i]['track']['duration_ms']\n",
    "        track_popularity = recent_tracks['items'][i]['track']['popularity']\n",
    "        played_at = pytz.utc.localize(datetime.strptime(recent_tracks['items'][i]['played_at'], '%Y-%m-%dT%H:%M:%S.%fZ')).astimezone(pytz.timezone('US/Pacific')).date()\n",
    "        played_at_unix = str(dp.parse(recent_tracks['items'][i]['played_at']).timestamp()).replace('.', '')  # Conversion from Standard ISO 8610 datetime to UNIX seconds\n",
    "        unique_id = played_at_unix + track_id\n",
    "\n",
    "        # Artist data\n",
    "        artist_name = recent_tracks['items'][i]['track']['album']['artists'][0]['name']\n",
    "        artist_url = recent_tracks['items'][i]['track']['album']['artists'][0]['external_urls']['spotify']\n",
    "        \n",
    "        # Album data\n",
    "        album_name = recent_tracks['items'][i]['track']['album']['name']\n",
    "        album_url = recent_tracks['items'][i]['track']['album']['external_urls']['spotify']\n",
    "        \n",
    "        # Additional artist and album data\n",
    "        token = ex.get_access_token()\n",
    "        artist_followers, artist_popularity, album_popularity, album_total_tracks, album_release_date = ex.additional_info(token, artist_id=artist_id, album_id=album_id)\n",
    "\n",
    "        # Play log fact table row\n",
    "        play_log_fact_data.append(\n",
    "            {\n",
    "                'time_track_key': unique_id, \n",
    "                'track_id': track_id,\n",
    "                'artist_id': artist_id,\n",
    "                'album_id': album_id,\n",
    "                'played_at': played_at, \n",
    "                'date_appended': curr_date\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Track dim table row\n",
    "        track_dim_data.append(\n",
    "            {\n",
    "                'track_id': track_id, \n",
    "                'track_name': track_name, \n",
    "                'track_url': track_url, \n",
    "                'track_length_ms': track_length_ms, \n",
    "                'track_popularity': track_popularity, \n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Artist dim table row\n",
    "        artist_dim_data.append(\n",
    "            {\n",
    "                'artist_id': artist_id,\n",
    "                'artist_name': artist_name,\n",
    "                'artist_url': artist_url,\n",
    "                'artist_followers': artist_followers,\n",
    "                'artist_popularity': artist_popularity\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Album dum table row\n",
    "        album_dim_data.append(\n",
    "            {\n",
    "                'album_id': album_id,\n",
    "                'album_name': album_name,\n",
    "                'album_url': album_url,\n",
    "                'album_popularity': album_popularity,\n",
    "                'album_total_tracks': album_total_tracks,\n",
    "                'album_release_date': album_release_date\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Creating DataFrames\n",
    "\n",
    "    # Play log fact table \n",
    "    play_log_fact_table = pd.DataFrame(play_log_fact_data)\n",
    "\n",
    "    # Track dim  table\n",
    "    track_dim_table = pd.DataFrame(track_dim_data)\n",
    "\n",
    "    # Artist dim table\n",
    "    artist_dim_table = pd.DataFrame(artist_dim_data)\n",
    "\n",
    "    # Album dim table\n",
    "    album_dim_table = pd.DataFrame(album_dim_data)\n",
    "    album_dim_table['album_release_date'] = album_dim_table['album_release_date'].astype('datetime64[ns]')\n",
    "\n",
    "    # Delete duplicate artists and albums from most recent 50 artists / albums\n",
    "    for table in [track_dim_table, artist_dim_table, album_dim_table]:\n",
    "        table.drop_duplicates(inplace=True)\n",
    "\n",
    "    return play_log_fact_table, track_dim_table, artist_dim_table, album_dim_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_log_fact_table, track_dim_table, artist_dim_table, album_dim_table = create_dataframes(recent_tracks=recent_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_update_tables(play_log_fact_table, track_dim_table, artist_dim_table, album_dim_table, hostname, database, username, pwd, port_id):\n",
    "    '''\n",
    "    Loads track, artist, and album DataFrames to specified PostgreSQL database. New data is appended to the respective tables and data is updated for non-static fields (e.g. popularity fields).\n",
    "\n",
    "    ARGUMENTS:\n",
    "        play_log_fact_table: Dataframe of recent tracks played data.\n",
    "        track_dim_table: DataFrame of track data from recent tracks played.\n",
    "        artist_dim_table: DataFrame of artist data from recent tracks played.\n",
    "        album_dim_table: DataFrame of album data from recent tracks played.\n",
    "        hostname: Host name credential for connecting to PostgreSQL.\n",
    "        database: Name of database containing artist, album, track tables in PostgreSQL.\n",
    "        username: Username credential for connecting to desired database in PostgreSQL.\n",
    "        pwd: Password credential for connecting to desired database in PostgreSQL.\n",
    "        port_id: Port number for connecting to desired database in PostgreSQL.\n",
    "    '''\n",
    "    # Connecting to postgreSQL database\n",
    "\n",
    "    # Instantiating connection as None to avoid errors with close if script executes incorrectly.\n",
    "    conn = None\n",
    "\n",
    "    # Create SQLAlchemy Engine for insert into database tables\n",
    "    engine = create_engine(f'postgresql://{username}:{pwd}@{hostname}:{port_id}/{database}')\n",
    "\n",
    "    # Creating connection object, opens database connection\n",
    "    try:\n",
    "        with psycopg2.connect(\n",
    "            host=hostname,\n",
    "            dbname=database,\n",
    "            user=username,\n",
    "            password=pwd,\n",
    "            port=port_id\n",
    "        ) as conn:\n",
    "            # cursor for storing return values\n",
    "            with conn.cursor() as cur:  # Cursor closes at end of with statement block\n",
    "                # SQL injection for each table\n",
    "                artist_sql =  {\n",
    "                    'dataframe': artist_dim_table,\n",
    "                    'data_table': 'artists',\n",
    "                    'staging_table': 'staging_artists', \n",
    "                    'primary_key': 'artist_id',\n",
    "                    'sql_injection_updates': 'artist_followers = S.artist_followers, artist_popularity = S.artist_popularity' \n",
    "                }\n",
    "                album_sql =  {\n",
    "                    'dataframe': album_dim_table,\n",
    "                    'data_table': 'albums',\n",
    "                    'staging_table': 'staging_albums', \n",
    "                    'primary_key': 'album_id',\n",
    "                    'sql_injection_updates': 'album_popularity = S.album_popularity, album_total_tracks = S.album_total_tracks' \n",
    "                }\n",
    "                track_sql = {\n",
    "                    'dataframe': track_dim_table,\n",
    "                    'data_table': 'tracks',\n",
    "                    'staging_table': 'staging_tracks',\n",
    "                    'primary_key': 'track_id',\n",
    "                    'sql_injection_updates': 'track_popularity = S.track_popularity'\n",
    "                }\n",
    "                log_sql = {\n",
    "                    'dataframe': play_log_fact_table,\n",
    "                    'data_table': 'play_log',\n",
    "                    'staging_table': 'play_log_staging',\n",
    "                    'primary_key': 'time_track_key',\n",
    "                }\n",
    "                # For each table, execute queries to update\n",
    "                for table in [artist_sql, album_sql, track_sql, log_sql]:\n",
    "                    # Append new data to staging table (to_sql creates table if not exists)\n",
    "                    table['dataframe'].to_sql(\n",
    "                        name=table['staging_table'],\n",
    "                        con=engine,\n",
    "                        if_exists='append',\n",
    "                        index=False\n",
    "                    )\n",
    "                    # Insert new data into main data table\n",
    "                    cur.execute(\n",
    "                    f'''\n",
    "                        INSERT INTO\n",
    "                            {table['data_table']}\n",
    "                        SELECT\n",
    "                            T.*\n",
    "                        FROM\n",
    "                            {table['staging_table']} T\n",
    "                            LEFT JOIN {table['data_table']} S ON\n",
    "                                T.{table['primary_key']} = S.{table['primary_key']}\n",
    "                        WHERE \n",
    "                            S.{table['primary_key']} IS NULL\n",
    "                        '''\n",
    "                    )\n",
    "                    # Update non-static fields\n",
    "                    if table != log_sql:  # Log table has no dynamic fields\n",
    "                        cur.execute(\n",
    "                        f'''\n",
    "                            UPDATE\n",
    "                                {table['data_table']} M\n",
    "                            SET\n",
    "                                {table['sql_injection_updates']}\n",
    "                            FROM\n",
    "                                {table['staging_table']} S\n",
    "                            WHERE\n",
    "                                M.{table['primary_key']} = S.{table['primary_key']}\n",
    "                            '''\n",
    "                        )\n",
    "                    else:\n",
    "                        pass\n",
    "                    # Truncate staging tables\n",
    "                    cur.execute(\n",
    "                    f'''\n",
    "                        TRUNCATE TABLE {table['staging_table']}\n",
    "                        '''\n",
    "                    )                \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "    finally:  # Always executes as part of try except.\n",
    "        if conn is not None:  # Close if not none\n",
    "        # Exit connection\n",
    "            conn.close()\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_update_tables(play_log_fact_table, track_dim_table, artist_dim_table, album_dim_table, hostname, database, username, pwd, port_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotipy_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5279c6fe171b71c479f9decce1e7e70192a43dd17f9c062e3597a4c4186e60e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
